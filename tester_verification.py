#!/usr/bin/env python3
"""
í…ŒìŠ¤í„° ë…ë¦½ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
SSH ì ‘ì† í›„ ì´ íŒŒì¼ì„ ì‹¤í–‰í•˜ì—¬ VModel AI ì„±ëŠ¥ì„ ë…ë¦½ì ìœ¼ë¡œ ê²€ì¦
"""

import json
import os
from datetime import datetime

def calculate_ktcc_metrics():
    """KTCC ê¸°ì¤€ì— ë”°ë¥¸ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
    
    print("ğŸ” VModel AI ì„±ëŠ¥ ì§€í‘œ ë…ë¦½ ê²€ì¦ ì‹œì‘...")
    
    # ì„±ëŠ¥ ë¡œê·¸ íŒŒì¼ ì½ê¸°
    performance_data = []
    try:
        with open("performance_data/performance_log.jsonl", "r", encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    performance_data.append(json.loads(line))
    except FileNotFoundError:
        print("âŒ ì„±ëŠ¥ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    if not performance_data:
        print("âŒ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê¸°ë³¸ í†µê³„
    total_tests = len(performance_data)
    successful_tests = sum(1 for record in performance_data if record['success'])
    completed_tests = sum(1 for record in performance_data if record['completed'])
    
    # KTCC ê¸°ì¤€ ê³„ì‚°
    accuracy = (successful_tests / total_tests) * 100 if total_tests > 0 else 0
    precision = (completed_tests / successful_tests) * 100 if successful_tests > 0 else 0
    recall = (completed_tests / total_tests) * 100 if total_tests > 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    # ì²˜ë¦¬ ì‹œê°„ ë¶„ì„
    processing_times = [record['total_time'] for record in performance_data if record['success']]
    avg_processing_time = sum(processing_times) / len(processing_times) if processing_times else 0
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š KTCC ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦ ê²°ê³¼")
    print("="*60)
    print(f"ğŸ“ˆ ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {total_tests}")
    print(f"âœ… ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {successful_tests}")
    print(f"ğŸ¯ ì™„ë£Œëœ í…ŒìŠ¤íŠ¸: {completed_tests}")
    print()
    print("ğŸ† ì„±ëŠ¥ ì§€í‘œ (75% ê¸°ì¤€):")
    print(f"   ğŸ“Š Accuracy: {accuracy:.1f}% {'âœ…' if accuracy >= 75 else 'âŒ'}")
    print(f"   ğŸ¯ Precision: {precision:.1f}% {'âœ…' if precision >= 75 else 'âŒ'}")
    print(f"   ğŸ“ˆ Recall: {recall:.1f}% {'âœ…' if recall >= 75 else 'âŒ'}")
    print(f"   ğŸ… F1-Score: {f1_score:.1f}% {'âœ…' if f1_score >= 75 else 'âŒ'}")
    print()
    print("â±ï¸ ì²˜ë¦¬ ì‹œê°„ (60ì´ˆ ê¸°ì¤€):")
    print(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_processing_time:.1f}ì´ˆ {'âœ…' if avg_processing_time <= 60 else 'âŒ'}")
    print()
    
    # ì „ì²´ ê¸°ì¤€ í†µê³¼ ì—¬ë¶€
    all_passed = (accuracy >= 75 and precision >= 75 and 
                 recall >= 75 and f1_score >= 75 and 
                 avg_processing_time <= 60)
    
    print("ğŸ¯ ìµœì¢… ê²°ê³¼:")
    if all_passed:
        print("   ğŸ† ëª¨ë“  KTCC ê¸°ì¤€ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
    else:
        print("   âŒ ì¼ë¶€ ê¸°ì¤€ì„ í†µê³¼í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
    print("="*60)
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1_score,
        'avg_processing_time': avg_processing_time,
        'all_passed': all_passed
    }

def show_raw_logs():
    """ì›ë³¸ ë¡œê·¸ íŒŒì¼ í‘œì‹œ"""
    print("\nğŸ“„ VModel API ì›ë³¸ ë¡œê·¸:")
    print("-" * 40)
    
    try:
        with open("logs/vmodel_api_raw.log", "r", encoding='utf-8') as f:
            content = f.read()
            print(content[-2000:])  # ë§ˆì§€ë§‰ 2000ìë§Œ í‘œì‹œ
    except FileNotFoundError:
        print("âŒ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def show_success_summary():
    """ì„±ê³µ/ì‹¤íŒ¨ ìš”ì•½ í‘œì‹œ"""
    print("\nğŸ“Š ì„±ê³µ/ì‹¤íŒ¨ ìš”ì•½:")
    print("-" * 40)
    
    try:
        with open("logs/success_failures.log", "r", encoding='utf-8') as f:
            lines = f.readlines()
            for line in lines[-10:]:  # ë§ˆì§€ë§‰ 10ê°œ ê²°ê³¼ë§Œ í‘œì‹œ
                print(line.strip())
    except FileNotFoundError:
        print("âŒ ìš”ì•½ ë¡œê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    import sys
    
    print("ğŸ”§ VModel AI í…ŒìŠ¤í„° ë…ë¦½ ê²€ì¦ ë„êµ¬")
    print("=" * 50)
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--metrics":
            calculate_ktcc_metrics()
        elif sys.argv[1] == "--logs":
            show_raw_logs()
        elif sys.argv[1] == "--summary":
            show_success_summary()
        else:
            print("ì‚¬ìš©ë²•: python tester_verification.py [--metrics|--logs|--summary]")
    else:
        # ì „ì²´ ê²€ì¦ ì‹¤í–‰
        calculate_ktcc_metrics()
        print("\n" + "="*60)
        show_success_summary()
